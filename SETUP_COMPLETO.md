# Setup Completo - Guia Passo a Passo

## ğŸš€ InstalaÃ§Ã£o RÃ¡pida com Makefile (Recomendado)

Se vocÃª jÃ¡ tem **make** e **docker** instalados:

```bash
# 1. Clonar o repositÃ³rio
git clone https://github.com/Wendemberg/Airflow-Dataops.git
cd Airflow-Dataops

# 2. Copiar .env
cp .env.example .env
# Configure as credenciais no .env

# 3. Subir containers
make docker-up

# 4. Executar pipeline
make pipeline

# 5. Ver dashboard
# Acesse: http://localhost:8501
```

**Ver todos os comandos**: `make help`

---

## ğŸ“– Setup Manual Detalhado

## PrÃ©-requisitos

Antes de comeÃ§ar, certifique-se de ter instalado:

- **Docker** (versÃ£o 20.10 ou superior)
- **Docker Compose** (versÃ£o 1.29 ou superior)
- **Git** (para clonar o repositÃ³rio)
- **Python 3.9+** (apenas se for executar scripts localmente)
- **Make** (opcional, para usar comandos automatizados)

### Verificar InstalaÃ§Ã£o

```bash
# Verificar Docker
docker --version
# Esperado: Docker version 20.10.x ou superior

# Verificar Docker Compose
docker-compose --version
# Esperado: docker-compose version 1.29.x ou superior

# Verificar Python (opcional)
python --version
# Esperado: Python 3.9.x ou superior

# Verificar Make (opcional)
make --version
# Esperado: GNU Make 3.x ou superior
```

---

## Passo 1: Clonar o RepositÃ³rio

```bash
# Clone o projeto
git clone <URL_DO_REPOSITORIO>

# Entre no diretÃ³rio
cd Dataops
```

---

## Passo 2: Configurar VariÃ¡veis de Ambiente

### 2.1 Criar arquivo .env

```bash
# Copiar o template
cp .env.example .env
```

### 2.2 Editar o arquivo .env

Abra o arquivo `.env` com seu editor favorito:

```bash
# Windows
notepad .env

# Linux/Mac
nano .env
# ou
vim .env
```

### 2.3 Preencher as credenciais

**IMPORTANTE**: Preencha com valores SEGUROS, nÃ£o use os exemplos abaixo em produÃ§Ã£o!

```env
# ========================================
# MinIO Configuration
# ========================================
MINIO_ACCESS_KEY=admin_dataops
MINIO_SECRET_KEY=SenhaSegura123!MinIO

# ========================================
# Label Studio Configuration
# ========================================
LABELSTUDIO_TOKEN=seu_token_aqui  # VocÃª vai obter isso no Passo 4
LABELSTUDIO_PROJECT=4

# ========================================
# Airflow Configuration
# ========================================
AIRFLOW_UID=50000
```

> **IMPORTANTE**: Deixe `LABELSTUDIO_TOKEN` vazio por enquanto. VocÃª vai preencher no Passo 4.

---

## Passo 3: Iniciar os Containers Docker

### 3.1 Build das imagens

```bash
# Build de todas as imagens
docker-compose build

# Isso pode demorar 5-10 minutos na primeira vez
```

### 3.2 Iniciar os serviÃ§os

```bash
# Iniciar todos os containers em background
docker-compose up -d

# Acompanhar logs (opcional)
docker-compose logs -f
```

### 3.3 Verificar status dos containers

```bash
# Verificar se todos estÃ£o rodando
docker-compose ps
```

**Esperado**:
```
NAME                    STATUS              PORTS
airflow-webserver       Up (healthy)        0.0.0.0:8080->8080/tcp
airflow-scheduler       Up (healthy)
airflow-triggerer       Up (healthy)
minio                   Up (healthy)        0.0.0.0:9000->9000/tcp, 0.0.0.0:9001->9001/tcp
label-studio            Up (healthy)        0.0.0.0:8001->8080/tcp
streamlit-dashboard     Up (healthy)        0.0.0.0:8501->8501/tcp
```

> **Aguarde**: Pode demorar 2-3 minutos atÃ© todos os containers ficarem "healthy"

---

## Passo 4: Configurar Label Studio e Obter Token LEGACY

### 4.1 Acessar Label Studio

Abra seu navegador e acesse:
```
http://localhost:8001
```

### 4.2 Criar Conta no Primeiro Acesso

**IMPORTANTE**: No primeiro acesso, vocÃª precisa criar uma conta.

#### Passo a passo:

1. **Acesse**: http://localhost:8001
2. **Clique em "Sign Up"** (se aparecer tela de login)
3. **Preencha o formulÃ¡rio de cadastro**:
   - **Email**: `label_ops@gmail.com`
   - **Password**: `dataops@123`
   - **Confirm Password**: `dataops@123`
4. **Clique em "Create Account"**

> **NOTA**: Se o Label Studio jÃ¡ tiver sido inicializado anteriormente e vocÃª vir uma tela de login, use as credenciais padrÃ£o:
> - **Email**: `admin@localhost.com`
> - **Senha**: `123456`
>
> Ou use as credenciais que vocÃª criou: `label_ops@gmail.com` / `dataops@123`

### 4.3 Configurar Legacy Token (IMPORTANTE!)

**ATENÃ‡ÃƒO**: O pipeline precisa do **LEGACY TOKEN**, nÃ£o do Access Token normal!

**Tutorial em vÃ­deo**: https://drive.google.com/file/d/11teN7OjPgbhWD17H0z4XPJ5pYhE3D4_j/view?usp=sharing

#### Passo a passo para configurar e obter o Legacy Token:

**Parte A: Habilitar Legacy Tokens (evitar expiraÃ§Ã£o)**

1. **No Label Studio, clique em "Organization"** (menu lateral esquerdo)
2. **Clique em "API Tokens Settings"**
3. **Desmarque todas as flags EXCETO "Legacy tokens"**
   - Deixe APENAS "Legacy tokens" marcado
   - Desmarque as outras opÃ§Ãµes (isso evita que o token expire)
4. **Clique em "Save"**

**Parte B: Gerar/Copiar o Legacy Token**

1. **Clique no Ã­cone do usuÃ¡rio** (canto superior direito)
2. **Clique em "Account & Settings"**
3. **Role atÃ© a seÃ§Ã£o "Access Token"**
4. **Procure por "Legacy API Token"** ou **"API Token (Legacy)"**
5. **Copie o token** (algo como: `a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6q7r8s9t0`)

> **IMPORTANTE**:
> - A configuraÃ§Ã£o em "Organization > API Tokens Settings" garante que o token nÃ£o expire
> - Deixar SOMENTE a flag "Legacy tokens" ativa Ã© FUNDAMENTAL
> - NÃ£o use o "Access Token" (JWT) - ele nÃ£o funciona com este pipeline
> - O Legacy Token tem formato: 40 caracteres hexadecimais
> - **Este token DEVE ser inserido no arquivo .env**

#### Imagem de referÃªncia:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Account & Settings                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ...                                    â”‚
â”‚                                        â”‚
â”‚ Access Token                           â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Legacy API Token (deprecated)      â”‚ â”‚
â”‚ â”‚ a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6... â”‚ â”‚ <- COPIE ESTE!
â”‚ â”‚ [Copy]                             â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.4 Atualizar .env com o Token

Edite o arquivo `.env` e cole o token:

```bash
# Editar .env
notepad .env  # Windows
nano .env     # Linux/Mac
```

Atualize a linha:
```env
LABELSTUDIO_TOKEN=a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6q7r8s9t0  # Cole seu token aqui
```

**IMPORTANTE**: Salve o arquivo apÃ³s inserir o token.

### 4.5 Reiniciar containers para aplicar o token

```bash
# Reiniciar para ler novo .env
docker-compose restart airflow-scheduler
docker-compose restart airflow-webserver
docker-compose restart streamlit
```

---

## Passo 5: Criar Projeto no Label Studio (se necessÃ¡rio)

**Tutorial em vÃ­deo**: https://drive.google.com/file/d/1sC-S7fQ0PFElqM8oX01OP-f2IsGlSrx_/view?usp=sharing

Se vocÃª nÃ£o tiver o projeto ID 4, crie um novo:

### 5.1 Criar novo projeto

1. No Label Studio, clique em **"Create Project"**
2. Nome: `DataOps NER Pipeline`
3. Em **"Labeling Setup"**, escolha **"Named Entity Recognition"**
4. Configure os labels:
   - `cliente`
   - `produto`
   - `quantidade`
   - `valor`
   - `canal`
   - `forma_pagamento`
   - `status`
   - `cidade`
   - `avaliacao`
   - `data`
   - `sentimento`

5. Clique em **"Save"**

### 5.2 Obter ID do projeto

1. Acesse o projeto criado
2. **Veja a URL no navegador**:
   ```
   http://localhost:8001/projects/3/data?tab=3
                                   â†‘
                             Este Ã© o ID do projeto
   ```
   - O nÃºmero apÃ³s `/projects/` Ã© o ID do projeto
   - No exemplo acima, o ID Ã© `3`

3. **IMPORTANTE: Atualize o `.env` com o ID correto**:
   ```env
   LABELSTUDIO_PROJECT=3  # Coloque o ID que aparece na sua URL
   ```

> **ATENÃ‡ÃƒO**: Ã‰ FUNDAMENTAL inserir o ID correto do projeto no arquivo `.env`, caso contrÃ¡rio o pipeline nÃ£o conseguirÃ¡ buscar os dados do Label Studio.

### 5.3 Importar Dataset do Projeto

**Dataset disponÃ­vel em**:
```
https://drive.google.com/drive/folders/1WFkw54HojR1y_Io26_cNV5ni3888I2FZ?usp=sharing
```

**Como importar**:

1. **Baixe o dataset** do Google Drive
2. **No Label Studio**, abra o projeto (ID 4)
3. **Clique em "Import"**
4. **Selecione os arquivos JSON** baixados
5. **Clique em "Import"**

**ConteÃºdo do dataset**:
- TransaÃ§Ãµes comerciais com dados estruturados
- AnotaÃ§Ãµes NER jÃ¡ realizadas (cliente, produto, valor, quantidade, etc.)
- 500 registros prontos para processamento

> **NOTA**: ApÃ³s importar, o dataset estarÃ¡ pronto para ser processado pelo pipeline Airflow.

---

## Passo 6: Verificar ServiÃ§os

Acesse cada serviÃ§o para verificar se estÃ¡ funcionando:

### 6.1 Airflow
```
URL: http://localhost:8080
Login: airflow
Senha: airflow
```

**O que verificar**:
- Interface do Airflow carrega
- DAGs aparecem na lista
- Nenhum erro nos logs

### 6.2 MinIO Console
```
URL: http://localhost:9001
Login: <seu MINIO_ACCESS_KEY do .env>
Senha: <seu MINIO_SECRET_KEY do .env>
```

**O que verificar**:
- Interface do MinIO carrega
- Buckets `bronze`, `silver`, `gold` e `inbox` existem

### 6.3 Label Studio
```
URL: http://localhost:8001
Login: label_ops@gmail.com
Senha: dataops@123
```

> **Ou se usou as credenciais padrÃ£o**: admin@localhost.com / 123456

**O que verificar**:
- Interface carrega
- Projeto aparece
- Token foi copiado corretamente

### 6.4 Streamlit Dashboard
```
URL: http://localhost:8501
(sem autenticaÃ§Ã£o)
```

**O que verificar**:
- Dashboard carrega
- Pode estar vazio se ainda nÃ£o houver dados (normal!)

---

## Passo 7: Executar Pipeline pela Primeira Vez

### OpÃ§Ã£o A: Executar via Airflow (Recomendado)

1. **Acesse Airflow**: http://localhost:8080

2. **Ative as DAGs**:
   - Localize `00_event_driven_ingestion`
   - Clique no toggle para ativar (fica azul)

3. **Trigger manual**:
   - Clique no Ã­cone de "play" na DAG
   - Clique em "Trigger DAG"

4. **Acompanhe execuÃ§Ã£o**:
   - Clique na DAG para ver detalhes
   - Veja as tasks sendo executadas em tempo real

### OpÃ§Ã£o B: Executar Scripts Manualmente (para teste)

Se quiser testar localmente (fora do Docker):

```bash
# Instalar dependÃªncias Python localmente
pip install -r requirements.txt

# Executar pipeline passo a passo
python -m scripts_pipeline.clean_buckets       # Limpar buckets
python -m scripts_pipeline.insert_bronze       # Inserir dados
python -m scripts_pipeline.transform_silver    # Transformar
python -m scripts_pipeline.aggregate_gold      # Agregar

# Ver diagnÃ³stico
python diagnose_data_flow.py
```

**SaÃ­da esperada no transform_silver.py**:
```
Detectado execuÃ§Ã£o local. Usando endpoint: localhost:9000

Extraindo labels NER e padronizando...

REGISTRO 0:
   [DEBUG] Processando 1 anotaÃ§Ã£o(Ãµes)
   [DEBUG] AnotaÃ§Ã£o 0 tem 5 resultado(s)
      [EXTRAÃDO] cliente: 'joÃ£o silva'
      [EXTRAÃDO] valor: '150.50'

Resumo de dados extraÃ­dos da API do Label Studio:

   EstatÃ­sticas de ExtraÃ§Ã£o NER:
      â€¢ Registros com algum NER: 500
      â€¢ Registros com 'cliente': 500
      â€¢ Registros com 'produto': 500
```

---

## Passo 8: Visualizar Dados no Dashboard

### OpÃ§Ã£o A: Via Docker (AutomÃ¡tico)

Se estiver usando Docker, o dashboard jÃ¡ estÃ¡ rodando. Acesse:
```
http://localhost:8501
```

### OpÃ§Ã£o B: ExecuÃ§Ã£o Local (Manual)

Se executou o pipeline localmente, apÃ³s os dados subirem para a camada Gold, execute:

```bash
# Ativar ambiente (se necessÃ¡rio)
conda activate dataops

# Executar dashboard
streamlit run streamlit\dashboard.py
```

**Acesse**: http://localhost:8501

**VocÃª deve ver**:
- KPIs agregados (se houver dados)
- Tabelas com registros
- GrÃ¡ficos Plotly
- Dados em tempo real

> **Se o dashboard estiver vazio**: Execute o pipeline primeiro (Passo 7)
>
> **IMPORTANTE**: O dashboard requer que o MinIO esteja rodando para acessar os dados da camada Gold

---

## Troubleshooting - Problemas Comuns

### Problema 1: Container nÃ£o inicia

**Sintoma**: `docker-compose ps` mostra container com status "Exited"

**SoluÃ§Ã£o**:
```bash
# Ver logs do container com problema
docker-compose logs <nome_do_container>

# Exemplo:
docker-compose logs label-studio
docker-compose logs minio
```

### Problema 2: "Failed to resolve 'minio'"

**Sintoma**: Erro ao executar scripts localmente

**SoluÃ§Ã£o**:
- JÃ¡ estÃ¡ corrigido! O sistema detecta automaticamente se estÃ¡ rodando local ou Docker
- Se ainda ocorrer, certifique que Docker estÃ¡ rodando: `docker ps`

### Problema 3: Label Studio nÃ£o aceita token

**Sintoma**: Erro 401 Unauthorized

**SoluÃ§Ã£o**:
1. Certifique que estÃ¡ usando **Legacy Token**, nÃ£o Access Token
2. Verifique se copiou o token completo (40 caracteres)
3. NÃ£o deixe espaÃ§os antes/depois do token no `.env`
4. Reinicie os containers: `docker-compose restart`

### Problema 4: Buckets MinIO nÃ£o existem

**Sintoma**: Erro "Bucket 'bronze' does not exist"

**SoluÃ§Ã£o**:
```bash
# Reexecutar inicializaÃ§Ã£o do MinIO
docker-compose restart minio-init

# Ver logs da inicializaÃ§Ã£o
docker-compose logs minio-init
```

### Problema 5: Port jÃ¡ em uso

**Sintoma**: "Port 8080 is already allocated"

**SoluÃ§Ã£o**:
```bash
# Parar processo que estÃ¡ usando a porta
# Windows:
netstat -ano | findstr :8080
taskkill /PID <PID> /F

# Linux/Mac:
lsof -i :8080
kill -9 <PID>

# Ou mudar porta no docker-compose.yml
```

### Problema 6: Credenciais incorretas

**Sintoma**: "Authentication failed"

**SoluÃ§Ã£o**:
```bash
# Verificar se .env foi lido corretamente
docker-compose config | grep MINIO_ACCESS_KEY

# Se vazio, o .env nÃ£o foi lido
# Certifique que:
# 1. .env estÃ¡ na raiz do projeto
# 2. NÃ£o tem espaÃ§os antes/depois do =
# 3. Reiniciou os containers
```

---

## Comandos Ãšteis

### Gerenciamento de Containers

```bash
# Ver logs em tempo real
docker-compose logs -f

# Ver logs de um serviÃ§o especÃ­fico
docker-compose logs -f streamlit

# Parar todos os containers
docker-compose stop

# Parar e remover containers
docker-compose down

# Reiniciar um serviÃ§o
docker-compose restart airflow-scheduler

# Executar comando dentro de um container
docker-compose exec streamlit bash
```

### Limpeza e Reset

```bash
# Parar e remover tudo (CUIDADO: deleta dados!)
docker-compose down -v

# Rebuild completo
docker-compose build --no-cache
docker-compose up -d
```

### Monitoramento

```bash
# Ver uso de recursos
docker stats

# Ver status de saÃºde
docker-compose ps

# Ver networks
docker network ls
docker network inspect dataops_dataops-network
```

---

## Checklist Final

Antes de considerar o setup completo, verifique:

**Containers**:
- Todos containers estÃ£o "Up (healthy)"
- Nenhum container em status "Exited"

**ConfiguraÃ§Ã£o**:
- .env criado com credenciais preenchidas
- LABELSTUDIO_TOKEN Ã© o Legacy Token (40 caracteres)
- LABELSTUDIO_PROJECT corresponde ao ID correto

**Acesso aos ServiÃ§os**:
- Airflow acessÃ­vel em http://localhost:8080
- MinIO acessÃ­vel em http://localhost:9001
- Label Studio acessÃ­vel em http://localhost:8001
- Streamlit acessÃ­vel em http://localhost:8501

**Funcionalidade**:
- DAG aparece no Airflow
- Buckets existem no MinIO (bronze, silver, gold, inbox)
- Projeto existe no Label Studio
- Pipeline executa sem erros

**Testes**:
- Executou pipeline manualmente (Passo 7)
- Dados aparecem no dashboard
- Logs nÃ£o mostram erros crÃ­ticos

---

## PrÃ³ximos Passos

Agora que o setup estÃ¡ completo:

1. **Adicione dados** ao Label Studio (projeto 4)
2. **Anote os dados** com as labels NER
3. **Execute o pipeline** via Airflow
4. **Visualize resultados** no dashboard

---

## Suporte

Se encontrar problemas:

1. Consulte a seÃ§Ã£o **Troubleshooting** acima
2. Verifique os logs: `docker-compose logs -f`

---

**Pronto!** Seu ambiente DataOps estÃ¡ configurado e funcionando!
