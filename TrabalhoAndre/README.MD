# ğŸ¬ Projeto Netflix Data Pipeline (Airflow + Streamlit + MinIO + Postgres)

Este projeto implementa um **pipeline de dados completo** para processar e analisar informaÃ§Ãµes do catÃ¡logo da Netflix, usando **Airflow** para orquestraÃ§Ã£o, **Postgres** para armazenamento, **MinIO** como Data Lake e **Streamlit** para visualizaÃ§Ã£o.

---

## ğŸ§± Arquitetura Implementada

### ğŸ”¹ Componentes Principais

| Componente | FunÃ§Ã£o |
|-------------|--------|
| **Airflow** | Orquestra o ETL completo dos dados Netflix (ingestÃ£o â†’ tratamento â†’ validaÃ§Ã£o â†’ load â†’ relatÃ³rio). |
| **Postgres** | Banco relacional que armazena os dados tratados. |
| **MinIO (S3 compatÃ­vel)** | Armazena os arquivos brutos, tratados e relatÃ³rios. |
| **Streamlit** | Dashboard interativo para visualizaÃ§Ã£o dos dados processados. |
| **Docker Compose** | Gerencia todos os serviÃ§os e dependÃªncias. |
| **Makefile** | Simplifica os comandos de execuÃ§Ã£o do ambiente. |

---

## âš™ï¸ DecisÃµes TÃ©cnicas

- Uso da **TaskFlow API** no Airflow para uma DAG mais legÃ­vel e modular.
- Armazenamento de arquivos em **Parquet** para eficiÃªncia de leitura e compressÃ£o.
- Upload automÃ¡tico dos resultados tratados e relatÃ³rios para o **MinIO**.
- CriaÃ§Ã£o automÃ¡tica da tabela `netflix_titles` no **Postgres**.
- Dashboard no **Streamlit** conectado diretamente ao MinIO, carregando os dados via `pandas.read_parquet()`.
- Logs e relatÃ³rios de execuÃ§Ã£o sÃ£o gerados automaticamente e salvos em `/data/processed/relatorios`.

---

## âš ï¸ LimitaÃ§Ãµes

- O Metabase estÃ¡ comentado no `docker-compose.yml` (pode ser ativado futuramente).
- A DAG deve ser executada manualmente no Airflow (nÃ£o possui agendamento automÃ¡tico).
- O ambiente foi projetado para uso **local** via Docker Compose, nÃ£o para produÃ§Ã£o.

---

## ğŸš€ Como Executar Localmente

### 1ï¸âƒ£ PrÃ©-requisitos

- **Docker** e **Docker Compose** instalados  
- **Make** instalado (jÃ¡ vem em Linux/Mac; no Windows use Git Bash)

### 2ï¸âƒ£ Clonar o repositÃ³rio

```bash
git clone <URL_DO_REPOSITORIO>
cd <PASTA_DO_PROJETO>
```

### 3ï¸âƒ£ Configurar variÃ¡veis de ambiente

Copie o arquivo de exemplo e ajuste se necessÃ¡rio:

```bash
cp infra/.env.example infra/.env
```
ğŸ’¡ As credenciais padrÃ£o jÃ¡ funcionam para execuÃ§Ã£o local.

### 4ï¸âƒ£ Subir o ambiente completo

```bash
make up
```

Isso iniciarÃ¡ os containers:

 - Airflow (webserver, scheduler e logs)

 - Postgres

 - MinIO

 - Streamlit

### 5ï¸âƒ£ Acessar as interfaces

| ServiÃ§o                 | URL                                            | UsuÃ¡rio/Senha               |
| ----------------------- | ---------------------------------------------- | --------------------------- |
| **Airflow**             | [http://localhost:8080](http://localhost:8080) | `admin` / `admin`           |
| **Streamlit Dashboard** | [http://localhost:8501](http://localhost:8501) | â€“                           |
| **MinIO Console**       | [http://localhost:9001](http://localhost:9001) | `minioadmin` / `minioadmin` |
| **Postgres**            | `localhost:5432`                               | `airflow` / `airflow`       |

---

## ğŸ”„ Como Executar o Pipeline (Airflow)

 1. Acesse o Airflow em http://localhost:8080

 2. Encontre a DAG fluxo_netflix

 3. Ative e clique em "Trigger DAG"

 4. O pipeline executarÃ¡ as seguintes etapas:

| Etapa                  | DescriÃ§Ã£o                                    |
| ---------------------- | -------------------------------------------- |
| `listar_csvs`          | LÃª os arquivos `.csv` em `data/raw`          |
| `carregar_e_tratar`    | Normaliza e limpa os dados                   |
| `anotar_dados`         | Calcula idade dos filmes e dias desde adiÃ§Ã£o |
| `salvar_parquet`       | Salva dataset tratado em `/data/processed`   |
| `validar_dados`        | Executa validaÃ§Ãµes de qualidade              |
| `enviar_para_minio`    | Envia parquet ao bucket S3 do MinIO          |
| `carregar_no_postgres` | Insere no banco Postgres                     |
| `gerar_relatorio`      | Gera relatÃ³rio de execuÃ§Ã£o e envia ao MinIO  |

---

## ğŸ§¾ Como Validar os Resultados

| Item                      | Onde Verificar                                                                    |
| ------------------------- | --------------------------------------------------------------------------------- |
| **Logs do Airflow**       | Na UI (task logs) ou `airflow/logs/` local                                        |
| **Arquivos tratados**     | `data/processed/netflix_titles_tratado.parquet`                                   |
| **RelatÃ³rio de execuÃ§Ã£o** | `data/processed/relatorios/relatorio_execucao.csv`                                |
| **Dashboard**             | [http://localhost:8501](http://localhost:8501) (carrega do MinIO automaticamente) |
| **Banco de Dados**        | Conecte-se ao Postgres e veja a tabela `netflix_titles`                           |

--- 

## ğŸ§ª Como Reproduzir um CenÃ¡rio de Teste

 1. Coloque um ou mais arquivos .csv na pasta data/raw/

 2. Execute o pipeline novamente no Airflow (Trigger DAG)

 3. Verifique:

  - Novos arquivos .parquet em /data/processed/

  - Upload no MinIO (processed/netflix_titles_tratado.parquet)

  - Dashboard atualizado automaticamente

---

## ğŸ§° Comandos Ãšteis (Makefile)

| Comando      | DescriÃ§Ã£o                                       |
| ------------ | ----------------------------------------------- |
| `make up`    | Sobe todo o ambiente (containers Docker)        |
| `make down`  | Derruba todos os containers                     |
| `make init`  | Inicializa apenas o banco Postgres              |
| `make reset` | Derruba tudo, limpa volumes e recria containers |
| `make logs`  | Mostra logs de todos os serviÃ§os                |

---

## ğŸ§¹ Parar e Limpar o Ambiente
```bash
make down
``` 
Se quiser apagar todos os dados e recomeÃ§ar do zero:
```bash
make reset
```

---

## ğŸ“Š Dashboard Netflix

O dashboard do Streamlit exibe:

 - LanÃ§amentos por ano

 - Top 10 paÃ­ses com mais tÃ­tulos

 - ProporÃ§Ã£o de filmes vs sÃ©ries

 - DistribuiÃ§Ã£o da idade dos tÃ­tulos

 - Tabela detalhada com filtros

Acesse em: http://localhost:8501

---

## ğŸ§© Estrutura do Projeto

```bash
.
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/                    # DAGs do Airflow (ETL Netflix)
â”‚   â”œâ”€â”€ app/                     # CÃ³digo Streamlit (dashboard)
â”‚   â”œâ”€â”€ logs/                    # Logs de execuÃ§Ã£o
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                     # Dados brutos (.csv)
â”‚   â”œâ”€â”€ processed/               # Dados tratados (.parquet + relatÃ³rios)
â”‚
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ docker-compose.yml       # Orquestra os serviÃ§os
â”‚   â”œâ”€â”€ .env.example             # VariÃ¡veis de ambiente
â”‚
â”œâ”€â”€ Makefile                     # Comandos simplificados
â””â”€â”€ README.md                    # DocumentaÃ§Ã£o do projeto

```

