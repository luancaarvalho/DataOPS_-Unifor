# üé¨ Projeto Netflix Data Pipeline (Airflow + Streamlit + MinIO + Postgres)

Este projeto implementa um **pipeline de dados completo** para processar e analisar informa√ß√µes do cat√°logo da Netflix, usando **Airflow** para orquestra√ß√£o, **Postgres** para armazenamento, **MinIO** como Data Lake e **Streamlit** para visualiza√ß√£o.

---

## üß± Arquitetura Implementada

### üîπ Componentes Principais

| Componente | Fun√ß√£o |
|-------------|--------|
| **Airflow** | Orquestra o ETL completo dos dados Netflix (ingest√£o ‚Üí tratamento ‚Üí valida√ß√£o ‚Üí load ‚Üí relat√≥rio). |
| **Postgres** | Banco relacional que armazena os dados tratados. |
| **MinIO (S3 compat√≠vel)** | Armazena os arquivos brutos, tratados e relat√≥rios. |
| **Streamlit** | Dashboard interativo para visualiza√ß√£o dos dados processados. |
| **Docker Compose** | Gerencia todos os servi√ßos e depend√™ncias. |
| **Makefile** | Simplifica os comandos de execu√ß√£o do ambiente. |

---

## ‚öôÔ∏è Decis√µes T√©cnicas

- Uso da **TaskFlow API** no Airflow para uma DAG mais leg√≠vel e modular.
- Armazenamento de arquivos em **Parquet** para efici√™ncia de leitura e compress√£o.
- Upload autom√°tico dos resultados tratados e relat√≥rios para o **MinIO**.
- Cria√ß√£o autom√°tica da tabela `netflix_titles` no **Postgres**.
- Dashboard no **Streamlit** conectado diretamente ao MinIO, carregando os dados via `pandas.read_parquet()`.
- Logs e relat√≥rios de execu√ß√£o s√£o gerados automaticamente e salvos em `/data/processed/relatorios`.

---

## ‚ö†Ô∏è Limita√ß√µes

- O Metabase est√° comentado no `docker-compose.yml` (pode ser ativado futuramente).
- A DAG deve ser executada manualmente no Airflow (n√£o possui agendamento autom√°tico).
- O ambiente foi projetado para uso **local** via Docker Compose, n√£o para produ√ß√£o.

---

## üöÄ Como Executar Localmente

### 1Ô∏è‚É£ Pr√©-requisitos

- **Docker** e **Docker Compose** instalados  
- **Make** instalado (j√° vem em Linux/Mac; no Windows use Git Bash)

### 2Ô∏è‚É£ Clonar o reposit√≥rio

```bash
git clone <URL_DO_REPOSITORIO>
cd <PASTA_DO_PROJETO>
```

### 3Ô∏è‚É£ Configurar vari√°veis de ambiente

Copie o arquivo de exemplo e ajuste se necess√°rio:

```bash
cp infra/.env.example infra/.env
```
üí° As credenciais padr√£o j√° funcionam para execu√ß√£o local.

### 4Ô∏è‚É£ Subir o ambiente completo

```bash
make up
```

Isso iniciar√° os containers:

 - Airflow (webserver, scheduler e logs)

 - Postgres

 - MinIO

 - Streamlit

### 5Ô∏è‚É£ Acessar as interfaces

| Servi√ßo                 | URL                                            | Usu√°rio/Senha               |
| ----------------------- | ---------------------------------------------- | --------------------------- |
| **Airflow**             | [http://localhost:8080](http://localhost:8080) | `admin` / `admin`           |
| **Streamlit Dashboard** | [http://localhost:8501](http://localhost:8501) | ‚Äì                           |
| **MinIO Console**       | [http://localhost:9001](http://localhost:9001) | `minioadmin` / `minioadmin` |
| **Postgres**            | `localhost:5432`                               | `airflow` / `airflow`       |

---

## üîÑ Como Executar o Pipeline (Airflow)

 1. Acesse o Airflow em http://localhost:8080

 2. Encontre a DAG fluxo_netflix

 3. Ative e clique em "Trigger DAG"

 4. O pipeline executar√° as seguintes etapas:

| Etapa                  | Descri√ß√£o                                    |
| ---------------------- | -------------------------------------------- |
| `listar_csvs`          | L√™ os arquivos `.csv` em `data/raw`          |
| `carregar_e_tratar`    | Normaliza e limpa os dados                   |
| `anotar_dados`         | Calcula idade dos filmes e dias desde adi√ß√£o |
| `salvar_parquet`       | Salva dataset tratado em `/data/processed`   |
| `validar_dados`        | Executa valida√ß√µes de qualidade              |
| `enviar_para_minio`    | Envia parquet ao bucket S3 do MinIO          |
| `carregar_no_postgres` | Insere no banco Postgres                     |
| `gerar_relatorio`      | Gera relat√≥rio de execu√ß√£o e envia ao MinIO  |

---

## üßæ Como Validar os Resultados

| Item                      | Onde Verificar                                                                    |
| ------------------------- | --------------------------------------------------------------------------------- |
| **Logs do Airflow**       | Na UI (task logs) ou `airflow/logs/` local                                        |
| **Arquivos tratados**     | `data/processed/netflix_titles_tratado.parquet`                                   |
| **Relat√≥rio de execu√ß√£o** | `data/processed/relatorios/relatorio_execucao.csv`                                |
| **Dashboard**             | [http://localhost:8501](http://localhost:8501) (carrega do MinIO automaticamente) |
| **Banco de Dados**        | Conecte-se ao Postgres e veja a tabela `netflix_titles`                           |

--- 

## üß™ Como Reproduzir um Cen√°rio de Teste

 1. Coloque um ou mais arquivos .csv na pasta data/raw/

 2. Execute o pipeline novamente no Airflow (Trigger DAG)

 3. Verifique:

  - Novos arquivos .parquet em /data/processed/

  - Upload no MinIO (processed/netflix_titles_tratado.parquet)

  - Dashboard atualizado automaticamente

---

## üß∞ Comandos √öteis (Makefile)

| Comando      | Descri√ß√£o                                       |
| ------------ | ----------------------------------------------- |
| `make up`    | Sobe todo o ambiente (containers Docker)        |
| `make down`  | Derruba todos os containers                     |
| `make init`  | Inicializa apenas o banco Postgres              |
| `make reset` | Derruba tudo, limpa volumes e recria containers |
| `make logs`  | Mostra logs de todos os servi√ßos                |

---

```bash
make down
``` 
Se quiser apagar todos os dados e recome√ßar do zero:
```bash
make reset
```

---

## üìä Dashboard Netflix

O dashboard do Streamlit exibe:

 - Lan√ßamentos por ano

 - Top 10 pa√≠ses com mais t√≠tulos

 - Propor√ß√£o de filmes vs s√©ries

 - Distribui√ß√£o da idade dos t√≠tulos

 - Tabela detalhada com filtros

Acesse em: http://localhost:8501

---

## üß© Estrutura do Projeto

```bash
.
‚îú‚îÄ‚îÄ airflow/
‚îÇ   ‚îú‚îÄ‚îÄ dags/                    # DAGs do Airflow (ETL Netflix)
‚îÇ   ‚îú‚îÄ‚îÄ app/                     # C√≥digo Streamlit (dashboard)
‚îÇ   ‚îú‚îÄ‚îÄ logs/                    # Logs de execu√ß√£o
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                     # Dados brutos (.csv)
‚îÇ   ‚îú‚îÄ‚îÄ processed/               # Dados tratados (.parquet + relat√≥rios)
‚îÇ
‚îú‚îÄ‚îÄ infra/
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml       # Orquestra os servi√ßos
‚îÇ   ‚îú‚îÄ‚îÄ .env.example             # Vari√°veis de ambiente
‚îÇ
‚îú‚îÄ‚îÄ Makefile                     # Comandos simplificados
‚îî‚îÄ‚îÄ README.md                    # Documenta√ß√£o do projeto

```

